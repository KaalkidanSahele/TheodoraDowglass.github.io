<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Data Science and Feminism</title>
    <script src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous" async></script>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">

    
    <style>
        
        
    </style>
  </head>
  <body>
	<script src="index.js"></script>

    <header>Data Science and Feminism</header>


    <h1>Data science gives us numbers we can use to definitevly demonstrate the work that still needs to be done to make the world more inclusive and safer for all</h1>

    <p>It is well known in the data science community that there is a bias issue with Big Data. It is incredibly susectible to pre-existing biases and prejudices in our society - this is easy to understand as we humans have produced this data and so it reflects the worst part of our opinions back at us.</p>
    <p>The issue comes along when we try to build ML models and other decision making software, which are intended to have frequent usage in our day to day life. While the purpose of these machines is to improve the efficiency of decisions which have to be made repeatedly, if they are fed data sets with the same bias as our society has then they will reflect this back at us. </p>

    <h2>Invisible women</h2>
    <p>A book by Caroline Criado perez describes the ways this has already had a negative impact on vulnerably communities
        [list 3 examples]</p>

    <h2> Joy Buolamwini</h2>
    <p>Founded the algorithmic justice league which who's MIT thesis uncovered large racial and gender bias in data used by Microsoft, IBM and amazon
        Helped make the film coded bias which talks about [list the issues the documentary brings up]</p>
    

    <h2>Data Feminism</h2>
    <p>Discusses pernicious feedback loop where areas which are poorer or match the stereotype of people likely to commit crime will be more heavily policed and so keeps the status quo in place</p>


    <p>We now have the raw numbers to show we need to do better. It's a shame we live in a world where we cannot rely on testimony to inspire people to make change but numbers don't lie so we now have a new tool in our arsenal to enact positve change. </p>

</body>
</html>

